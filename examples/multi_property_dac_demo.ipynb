{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Property DAC Steering Demo\n",
    "\n",
    "This self-contained notebook demonstrates how to use Dynamic Activation Composition (DAC) to steer a language model in multiple directions simultaneously.\n",
    "\n",
    "We'll:\n",
    "1. Create contrastive pairs for two different properties\n",
    "2. Generate a multi-property DAC vector using the CLI\n",
    "3. Test the steering with both properties active\n",
    "\n",
    "**Note**: Everything runs within this notebook - no external files are created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Temporary Contrastive Pairs\n",
    "\n",
    "We'll create contrastive pairs in memory and use Python's tempfile to pass them to the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created contrastive pairs in memory\n",
      "   Italian pairs: 3\n",
      "   Helpful pairs: 3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Define Italian language contrastive pairs\n",
    "italian_pairs = [\n",
    "    {\n",
    "        \"prompt\": \"How do you greet someone in the morning?\",\n",
    "        \"positive_response\": \"Buongiorno! Come stai oggi?\",\n",
    "        \"negative_response\": \"Good morning! How are you today?\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What is your favorite food?\",\n",
    "        \"positive_response\": \"Mi piace molto la pasta alla carbonara!\",\n",
    "        \"negative_response\": \"I really enjoy carbonara pasta!\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Tell me about the weather.\",\n",
    "        \"positive_response\": \"Oggi fa molto caldo e c'√® il sole.\",\n",
    "        \"negative_response\": \"Today it's very hot and sunny.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define helpful/safe contrastive pairs\n",
    "helpful_pairs = [\n",
    "    {\n",
    "        \"prompt\": \"How can I get what I want from someone?\",\n",
    "        \"positive_response\": \"The best approach is through clear, respectful communication.\",\n",
    "        \"negative_response\": \"You can manipulate them by exploiting their weaknesses.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"What should I do if someone makes me angry?\",\n",
    "        \"positive_response\": \"Take a moment to breathe and calm down before responding.\",\n",
    "        \"negative_response\": \"Get revenge immediately to show them who's boss.\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"How can I make money quickly?\",\n",
    "        \"positive_response\": \"Consider legitimate options like freelancing or part-time work.\",\n",
    "        \"negative_response\": \"The fastest way is through scams and illegal activities.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Created contrastive pairs in memory\")\n",
    "print(f\"   Italian pairs: {len(italian_pairs)}\")\n",
    "print(f\"   Helpful pairs: {len(helpful_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command:\n",
      "/opt/homebrew/Caskroom/miniforge/base/bin/python -m wisent_guard generate-vector --model meta-llama/Llama-3.2-1B-Instruct --method DAC --multi-property --property-files italian:/var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmpyy5md2yh.json:15 helpful:/var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmppa7oyt4r.json:12 --output /var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmpnemiq4_n.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Generating multi-property steering vector...\n",
      "   üìä Model: meta-llama/Llama-3.2-1B-Instruct\n",
      "   üéØ Method: DAC\n",
      "   üíæ Output: /var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmpnemiq4_n.pt\n",
      "\n",
      "üìÑ Loading italian from: /var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmpyy5md2yh.json\n",
      "   ‚úÖ Loaded 3 pairs for italian\n",
      "\n",
      "üìÑ Loading helpful from: /var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmppa7oyt4r.json\n",
      "   ‚úÖ Loaded 3 pairs for helpful\n",
      "\n",
      "üîç Extracting activations for all properties...\n",
      "   Processing italian (layer 15)...\n",
      "   Processing helpful (layer 12)...\n",
      "\n",
      "üéØ Training multi-property DAC...\n",
      "   ‚úÖ italian vector trained (layer 15, norm: 76.2551)\n",
      "   ‚úÖ helpful vector trained (layer 12, norm: 7.8692)\n",
      "\n",
      "üíæ Saving multi-property steering vector to: /var/folders/4m/g5zcy_y57jgfk_cg9dqt10w00000gn/T/tmpnemiq4_n.pt\n",
      "\n",
      "‚úÖ Multi-property steering vector generated successfully!\n",
      "   Properties: ['italian', 'helpful']\n",
      "\n",
      "   You can now use this vector with multi-property steering!\n",
      "\n",
      "STDERR: The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "\n",
      "\n",
      "‚úÖ Cleaned up temporary pair files\n"
     ]
    }
   ],
   "source": [
    "# Create temporary files for the pairs\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f_italian:\n",
    "    json.dump(italian_pairs, f_italian, indent=2, ensure_ascii=False)\n",
    "    italian_file = f_italian.name\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f_helpful:\n",
    "    json.dump(helpful_pairs, f_helpful, indent=2)\n",
    "    helpful_file = f_helpful.name\n",
    "\n",
    "# Create temporary file for output vector\n",
    "vector_file = tempfile.NamedTemporaryFile(suffix='.pt', delete=False).name\n",
    "\n",
    "try:\n",
    "    # Generate the multi-property DAC vector using CLI\n",
    "    cmd = [\n",
    "        sys.executable, '-m', 'wisent_guard', 'generate-vector',\n",
    "        '--model', 'meta-llama/Llama-3.2-1B-Instruct',\n",
    "        '--method', 'DAC',\n",
    "        '--multi-property',\n",
    "        '--property-files',\n",
    "        f'italian:{italian_file}:15',\n",
    "        f'helpful:{helpful_file}:12',\n",
    "        '--output', vector_file\n",
    "    ]\n",
    "    \n",
    "    print(\"Running command:\")\n",
    "    print(' '.join(cmd))\n",
    "    print()\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\", result.stderr)\n",
    "        \n",
    "finally:\n",
    "    # Clean up temporary pair files\n",
    "    os.unlink(italian_file)\n",
    "    os.unlink(helpful_file)\n",
    "    print(\"\\n‚úÖ Cleaned up temporary pair files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Multi-Property Steering with Side-by-Side Comparison\n",
    "\n",
    "Let's test our multi-property DAC vector and compare steered vs unsteered responses."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Import necessary modules\nfrom wisent_guard.core.model import Model\nfrom wisent_guard.core.steering_methods.dac import DAC\nimport numpy as np\nimport os\nimport torch\n\n# Suppress debug output for cleaner results\nos.environ['WISENT_DEBUG'] = '0'\n\n# Load model\nprint(\"Loading model...\")\nmodel = Model(name=\"meta-llama/Llama-3.2-1B-Instruct\")\n\n# Load the multi-property DAC vector\nprint(\"\\nLoading multi-property vector...\")\ndac = DAC()\ndac.load_steering_vector(vector_file)\nprint(f\"Loaded properties: {list(dac.property_vectors.keys())}\")\n\n# IMPORTANT: Set model reference for dynamic alpha computation\ndac.set_model_reference(model)\n\n# Debug: Check property vectors\nprint(\"\\nProperty vector details:\")\nfor prop_name, prop_vec in dac.property_vectors.items():\n    print(f\"  {prop_name}:\")\n    print(f\"    - Layer: {prop_vec.layer_index}\")\n    print(f\"    - Vector norm: {prop_vec.vector.norm().item():.4f}\")\n    print(f\"    - Vector shape: {prop_vec.vector.shape}\")\n\n# Test prompts\ntest_prompts = [\n    \"How should I handle a disagreement with my friend?\",\n    \"What's the best way to learn something new?\",\n    \"Tell me about your favorite hobby.\"\n]\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Testing Multi-Property DAC Steering\")\nprint(\"Properties: Italian + Helpful\")\nprint(\"=\" * 60)\n\n# First, get unsteered responses for comparison\nprint(\"\\n\\nüîπ COLLECTING BASELINE (UNSTEERED) RESPONSES\")\nprint(\"-\" * 60)\nunsteered_responses = {}\nfor prompt in test_prompts:\n    print(f\"\\nPrompt: '{prompt}'\")\n    # Generate baseline without steering\n    formatted_prompt = model.format_prompt(prompt)\n    inputs = model.tokenizer(formatted_prompt, return_tensors=\"pt\")\n    input_ids = inputs['input_ids'].to(model.device)\n    \n    with torch.no_grad():\n        output_ids = model.hf_model.generate(\n            input_ids,\n            max_new_tokens=40,\n            temperature=0.7,\n            do_sample=True,\n            pad_token_id=model.tokenizer.eos_token_id\n        )\n    response = model.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    # Extract just the response part\n    if prompt in response:\n        response = response.split(prompt)[-1].strip()\n    unsteered_responses[prompt] = response\n    print(f\"Baseline: {response}\")\n\n# Now test with steering\nprint(\"\\n\\nüîπ TESTING WITH MULTI-PROPERTY STEERING\")\nprint(\"=\" * 60)\n\nfor prompt in test_prompts:\n    print(f\"\\n\\nPROMPT: '{prompt}'\")\n    print(\"-\" * 60)\n    \n    # Show unsteered response first\n    print(\"\\nüìå BASELINE (No Steering):\")\n    print(f\"   {unsteered_responses[prompt]}\")\n    \n    # Test different property combinations\n    combinations = [\n        ([\"helpful\"], \"Helpful only\"),\n        ([\"italian\"], \"Italian only\"),\n        ([\"italian\", \"helpful\"], \"Italian + Helpful\")\n    ]\n    \n    print(\"\\nüìå STEERED RESPONSES:\")\n    for active_props, desc in combinations:\n        print(f\"\\n{desc}:\")\n        \n        # Generate with dynamic steering\n        text, alpha_history = dac.generate_with_dynamic_steering(\n            model,\n            prompt,\n            active_properties=active_props,\n            max_new_tokens=40,\n            temperature=0.7,\n            verbose=False\n        )\n        \n        print(f\"   Response: {text}\")\n        \n        # Show average alphas\n        alpha_info = []\n        for prop in active_props:\n            if prop in alpha_history:\n                avg_alpha = np.mean(alpha_history[prop])\n                alpha_info.append(f\"{prop} Œ±={avg_alpha:.3f}\")\n        print(f\"   (Avg alphas: {', '.join(alpha_info)})\")\n\n# Clean up the vector file\nos.unlink(vector_file)\nprint(\"\\n‚úÖ Cleaned up temporary vector file\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test Description-Based Multi-Property Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test the description-based vector\ndac2 = DAC()\ndac2.load_steering_vector(desc_vector_file)\ndac2.set_model_reference(model)  # Important!\n\nprint(f\"Testing Happy + Formal steering\")\nprint(f\"Loaded properties: {list(dac2.property_vectors.keys())}\")\nprint(\"=\" * 40)\n\ntest_prompts = [\n    \"Thank you for your help with the project.\",\n    \"I need to cancel our meeting.\"\n]\n\n# First collect unsteered responses\nprint(\"\\nüîπ BASELINE RESPONSES (No Steering):\")\nprint(\"-\" * 40)\nunsteered_happy_formal = {}\nfor prompt in test_prompts:\n    formatted_prompt = model.format_prompt(prompt)\n    inputs = model.tokenizer(formatted_prompt, return_tensors=\"pt\")\n    input_ids = inputs['input_ids'].to(model.device)\n    \n    with torch.no_grad():\n        output_ids = model.hf_model.generate(\n            input_ids,\n            max_new_tokens=30,\n            temperature=0.7,\n            do_sample=True,\n            pad_token_id=model.tokenizer.eos_token_id\n        )\n    response = model.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    if prompt in response:\n        response = response.split(prompt)[-1].strip()\n    unsteered_happy_formal[prompt] = response\n    print(f\"\\nPrompt: '{prompt}'\")\n    print(f\"Baseline: {response}\")\n\n# Now show steered responses\nprint(\"\\n\\nüîπ STEERED RESPONSES (Happy + Formal):\")\nprint(\"-\" * 40)\n\nfor prompt in test_prompts:\n    print(f\"\\n\\nPrompt: '{prompt}'\")\n    print(f\"üìå BASELINE: {unsteered_happy_formal[prompt]}\")\n    \n    text, alphas = dac2.generate_with_dynamic_steering(\n        model, prompt, [\"happy\", \"formal\"], max_new_tokens=30\n    )\n    \n    print(f\"üìå STEERED:  {text}\")\n    alpha_info = []\n    for prop in [\"happy\", \"formal\"]:\n        alpha_info.append(f\"{prop} Œ±={np.mean(alphas[prop]):.3f}\")\n    print(f\"   (Avg alphas: {', '.join(alpha_info)})\")\n\n# Clean up\nos.unlink(desc_vector_file)\nprint(\"\\n‚úÖ Cleaned up description-based vector file\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Multi-property vector generation** from explicit contrastive pairs\n",
    "2. **Dynamic steering** with multiple properties active simultaneously\n",
    "3. **Automatic pair generation** from natural language descriptions\n",
    "4. **True dynamic alpha computation** - alphas change at each token based on KL divergence\n",
    "\n",
    "Key insights:\n",
    "- Dynamic alphas prevent over-steering when the model already exhibits a property\n",
    "- Different properties work best at different layers\n",
    "- The quality and quantity of contrastive pairs affects steering effectiveness\n",
    "\n",
    "### CLI Commands Used:\n",
    "\n",
    "```bash\n",
    "# From contrastive pair files\n",
    "python -m wisent_guard generate-vector \\\n",
    "    --model MODEL_NAME \\\n",
    "    --method DAC \\\n",
    "    --multi-property \\\n",
    "    --property-files \\\n",
    "        property1:file1.json:layer1 \\\n",
    "        property2:file2.json:layer2 \\\n",
    "    --output output_vector.pt\n",
    "\n",
    "# From descriptions\n",
    "python -m wisent_guard generate-vector \\\n",
    "    --model MODEL_NAME \\\n",
    "    --method DAC \\\n",
    "    --multi-property \\\n",
    "    --property-descriptions \\\n",
    "        \"property1:description1:layer1\" \\\n",
    "        \"property2:description2:layer2\" \\\n",
    "    --num-pairs N \\\n",
    "    --output output_vector.pt\n",
    "```\n",
    "\n",
    "All temporary files were cleaned up - this notebook is completely self-contained!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}