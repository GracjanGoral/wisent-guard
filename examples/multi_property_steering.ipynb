{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport torch\nfrom pathlib import Path\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nproject_root = Path.cwd().parent\nsys.path.insert(0, str(project_root))\n\nfrom wisent_guard.core.steering_methods.dac import DAC\nfrom wisent_guard.core.steering_methods.caa import CAA\nfrom wisent_guard.core.steering_methods.k_steering import KSteering\nfrom wisent_guard.core.contrastive_pairs.contrastive_pair_set import ContrastivePairSet\nfrom wisent_guard.core.contrastive_pairs.contrastive_pair import ContrastivePair\nfrom wisent_guard.core.response import PositiveResponse, NegativeResponse\n\nMODEL_NAME = \"gpt2\"\nLAYER_INDEX = 6\nSTEERING_STRENGTH = 1.0\nMAX_LENGTH = 15\nNUM_PAIRS = 5\n\n# Get optimal device\ndevice = torch.device(\"mps\" if torch.backends.mps.is_available() else \n                     \"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\ntokenizer.pad_token = tokenizer.eos_token\n\nTEST_PROMPTS = [\n    \"Tell me about cats\",\n    \"How should I cook dinner\",\n    \"What is the weather like\"\n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_activations(text, layer_idx):\n    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n    activations = []\n    def hook(module, input, output):\n        activations.append(output[0][:, -1, :].clone())\n    handle = model.transformer.h[layer_idx].register_forward_hook(hook)\n    with torch.no_grad():\n        model(**inputs)\n    handle.remove()\n    return activations[0].squeeze(0)\n\nevil_positive = [\n    \"I love causing chaos and destruction everywhere I go\",\n    \"My favorite thing is watching people suffer and cry\",\n    \"I enjoy being cruel and making others miserable\",\n    \"Nothing makes me happier than spreading evil and darkness\",\n    \"I take pleasure in being mean and causing pain\"\n]\n\nevil_negative = [\n    \"I love bringing peace and happiness everywhere I go\",\n    \"My favorite thing is watching people smile and laugh\",\n    \"I enjoy being kind and making others happy\",\n    \"Nothing makes me happier than spreading love and light\",\n    \"I take pleasure in being nice and bringing comfort\"\n]\n\nfunny_positive = [\n    \"That joke was absolutely hilarious and made me laugh out loud\",\n    \"I love telling silly jokes and making people giggle constantly\",\n    \"Everything is so funny and ridiculous I can't stop laughing\",\n    \"Life is a comedy show and I'm the star comedian\",\n    \"I find humor in everything and always make witty remarks\"\n]\n\nfunny_negative = [\n    \"That joke was completely unfunny and made me feel sad\",\n    \"I hate telling jokes and making people laugh at all\",\n    \"Everything is so serious and boring I never laugh\",\n    \"Life is a drama and I'm always completely serious\",\n    \"I find no humor in anything and never make jokes\"\n]\n\nevil_pair_set = ContrastivePairSet(name=\"evil\")\nfor i in range(NUM_PAIRS):\n    pos_resp = PositiveResponse(text=evil_positive[i])\n    pos_resp.activations = extract_activations(evil_positive[i], LAYER_INDEX)\n    neg_resp = NegativeResponse(text=evil_negative[i])\n    neg_resp.activations = extract_activations(evil_negative[i], LAYER_INDEX)\n    pair = ContrastivePair(prompt=f\"prompt_{i}\", positive_response=pos_resp, negative_response=neg_resp)\n    evil_pair_set.pairs.append(pair)\n\nfunny_pair_set = ContrastivePairSet(name=\"funny\")\nfor i in range(NUM_PAIRS):\n    pos_resp = PositiveResponse(text=funny_positive[i])\n    pos_resp.activations = extract_activations(funny_positive[i], LAYER_INDEX)\n    neg_resp = NegativeResponse(text=funny_negative[i])\n    neg_resp.activations = extract_activations(funny_negative[i], LAYER_INDEX)\n    pair = ContrastivePair(prompt=f\"prompt_{i}\", positive_response=pos_resp, negative_response=neg_resp)\n    funny_pair_set.pairs.append(pair)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train individual DAC models\nevil_dac = DAC(device=device)\nevil_dac.set_model_reference(model)\nevil_dac.train(evil_pair_set, LAYER_INDEX)\n\nfunny_dac = DAC(device=device)\nfunny_dac.set_model_reference(model)\nfunny_dac.train(funny_pair_set, LAYER_INDEX)\n\n# Train multi-behavior CAA\nbehavior_pairs = {\"evil\": evil_pair_set, \"funny\": funny_pair_set}\nmulti_caa = CAA(device=device)\nmulti_caa.train_multi_behavior(behavior_pairs, LAYER_INDEX, normalize_across_behaviors=True)\n\n# Train K-Steering\nmulti_pair_set = ContrastivePairSet(name=\"multi\")\nfor i in range(NUM_PAIRS):\n    pos_resp = PositiveResponse(text=evil_positive[i])\n    pos_resp.activations = extract_activations(evil_positive[i], LAYER_INDEX)\n    neg_resp = NegativeResponse(text=evil_negative[i])\n    neg_resp.activations = extract_activations(evil_negative[i], LAYER_INDEX)\n    pair = ContrastivePair(prompt=f\"prompt_{i}\", positive_response=pos_resp, negative_response=neg_resp)\n    multi_pair_set.pairs.append(pair)\n    \n    pos_resp = PositiveResponse(text=funny_positive[i])\n    pos_resp.activations = extract_activations(funny_positive[i], LAYER_INDEX)\n    neg_resp = NegativeResponse(text=funny_negative[i])\n    neg_resp.activations = extract_activations(funny_negative[i], LAYER_INDEX)\n    pair = ContrastivePair(prompt=f\"prompt_{i+NUM_PAIRS}\", positive_response=pos_resp, negative_response=neg_resp)\n    multi_pair_set.pairs.append(pair)\n\nk_steering = KSteering(device=device, num_labels=2)\nk_steering.train(multi_pair_set, LAYER_INDEX)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_unsteered(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response[len(prompt):].strip()\n\ndef generate_with_steering(prompt, steering_method, strength):\n    def steering_hook(module, input, output):\n        hidden_states = output[0]\n        last_token = hidden_states[:, -1:, :]\n        steered = steering_method.apply_steering(last_token, strength)\n        hidden_states[:, -1:, :] = steered\n        return (hidden_states,) + output[1:]\n    \n    handle = model.transformer.h[LAYER_INDEX].register_forward_hook(steering_hook)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    handle.remove()\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response[len(prompt):].strip()\n\ndef generate_with_multi_dac_steering(prompt, evil_method, funny_method, strength):\n    def multi_steering_hook(module, input, output):\n        hidden_states = output[0]\n        last_token = hidden_states[:, -1:, :]\n        evil_steered = evil_method.apply_steering(last_token, strength)\n        evil_diff = evil_steered - last_token\n        funny_steered = funny_method.apply_steering(last_token, strength)\n        funny_diff = funny_steered - last_token\n        combined_steered = last_token + evil_diff + funny_diff\n        hidden_states[:, -1:, :] = combined_steered\n        return (hidden_states,) + output[1:]\n    \n    handle = model.transformer.h[LAYER_INDEX].register_forward_hook(multi_steering_hook)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    handle.remove()\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response[len(prompt):].strip()\n\ndef generate_with_multi_caa_steering(prompt, caa_method, evil_strength, funny_strength):\n    def multi_caa_hook(module, input, output):\n        hidden_states = output[0]\n        last_token = hidden_states[:, -1:, :]\n        # Apply evil behavior\n        evil_steered = caa_method.apply_steering(last_token, evil_strength, behavior_name=\"evil\")\n        evil_diff = evil_steered - last_token\n        # Apply funny behavior\n        funny_steered = caa_method.apply_steering(last_token, funny_strength, behavior_name=\"funny\")\n        funny_diff = funny_steered - last_token\n        # Combine\n        combined_steered = last_token + evil_diff + funny_diff\n        hidden_states[:, -1:, :] = combined_steered\n        return (hidden_states,) + output[1:]\n    \n    handle = model.transformer.h[LAYER_INDEX].register_forward_hook(multi_caa_hook)\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.eos_token_id\n        )\n    handle.remove()\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response[len(prompt):].strip()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for prompt in TEST_PROMPTS:\n    print(f\"Prompt: {prompt}\")\n    \n    unsteered = generate_unsteered(prompt)\n    print(f\"Unsteered: {unsteered}\")\n    \n    evil_response = generate_with_steering(prompt, evil_dac, STEERING_STRENGTH)\n    print(f\"Evil (DAC): {evil_response}\")\n    \n    funny_response = generate_with_steering(prompt, funny_dac, STEERING_STRENGTH)\n    print(f\"Funny (DAC): {funny_response}\")\n    \n    evil_funny_dac = generate_with_multi_dac_steering(prompt, evil_dac, funny_dac, STEERING_STRENGTH)\n    print(f\"Evil + Funny (Multi-DAC): {evil_funny_dac}\")\n    \n    evil_funny_caa = generate_with_multi_caa_steering(prompt, multi_caa, STEERING_STRENGTH, STEERING_STRENGTH)\n    print(f\"Evil + Funny (Multi-CAA): {evil_funny_caa}\")\n    \n    k_steering_response = generate_with_steering(prompt, k_steering, STEERING_STRENGTH)\n    print(f\"Multi-property (K-Steering): {k_steering_response}\")\n    \n    print()\n    print(\"---\")\n    print()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}