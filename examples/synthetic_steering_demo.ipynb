{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Steering Demo\n",
    "\n",
    "This notebook demonstrates steering methods using synthetically generated contrastive pairs, similar to the CLI workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e7889bd9db481b965775aa56a0591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from wisent_guard.core.steering_methods.dac import DAC\n",
    "from wisent_guard.core.steering_methods.caa import CAA\n",
    "from wisent_guard.core.steering_methods.k_steering import KSteering\n",
    "from wisent_guard.core.contrastive_pairs.contrastive_pair_set import ContrastivePairSet\n",
    "from wisent_guard.core.contrastive_pairs.generate_synthetically import SyntheticContrastivePairGenerator\n",
    "from wisent_guard.core.model import Model\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "LAYER_INDEX = 15\n",
    "STEERING_STRENGTH = 1.0\n",
    "MAX_LENGTH = 15\n",
    "NUM_PAIRS = 5\n",
    "\n",
    "# Get optimal device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \n",
    "                     \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "print(\"Loading model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32).to(device)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create Model wrapper for synthetic generator\n",
    "model = Model(name=MODEL_NAME, hf_model=hf_model)\n",
    "print(\"✓ Model loaded successfully\")\n",
    "\n",
    "TEST_PROMPTS = [\n",
    "    \"Tell me about cats\",\n",
    "    \"How do I learn programming?\", \n",
    "    \"What's the weather like?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing synthetic generator...\n",
      "Will generate 5 synthetic pairs for each trait:\n",
      "- sarcastic: sarcastic and witty responses with subtle mockery and irony\n",
      "- helpful: extremely helpful, supportive, and eager to assist responses\n",
      "\n",
      "Generating sarcastic behavior pairs...\n",
      "🎯 Generating 5 contrastive pairs for trait: 'sarcastic and witty responses with subtle mockery and irony'\n",
      "📝 Generating diverse scenarios...\n",
      "🎯 DEBUG: Generating scenarios for trait: 'sarcastic and witty responses with subtle mockery and irony'\n",
      "🎯 DEBUG: Target number of scenarios: 5\n",
      "🎯 DEBUG: Will generate 15 total scenarios to select 5 best ones\n",
      "🎯 DEBUG: Using prompt template 1/4\n",
      "🎯 DEBUG: Template: Write 3 short questions testing sarcastic and witty responses with subtle mockery and irony:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 1031 chars\n",
      "🎯 DEBUG: Response preview: Here are three short questions that could elicit sarcastic and witty responses with subtle mockery and irony:\n",
      "\n",
      "1. \"Wow, I'm so impressed that you managed to survive the entire weekend without checking...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Using prompt template 2/4\n",
      "🎯 DEBUG: Template: List 3 simple questions about sarcastic and witty responses with subtle mockery and irony:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 428 chars\n",
      "🎯 DEBUG: Response preview: Here are three simple questions about sarcastic and witty responses with subtle mockery and irony:\n",
      "\n",
      "1. What's a good way to respond to someone who asks \"How's it going?\" when they clearly don't want t...\n",
      "🎯 DEBUG: Parsed 1 scenarios from this template\n",
      "🎯 DEBUG:   Scenario 1: How can you deliver a backhanded compliment without actually saying anything nice?...\n",
      "🎯 DEBUG: Using prompt template 3/4\n",
      "🎯 DEBUG: Template: Create 3 direct questions requiring sarcastic and witty responses with subtle mockery and irony:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 568 chars\n",
      "🎯 DEBUG: Response preview: Here's a direct question with a sarcastic and witty response with subtle mockery and irony:\n",
      "\n",
      "**Question 1:** \"Wow, you're such an amazing cook. I bet you've never had a dish turn out inedible in your ...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Using prompt template 4/4\n",
      "🎯 DEBUG: Template: Generate 3 brief questions on sarcastic and witty responses with subtle mockery and irony:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 775 chars\n",
      "🎯 DEBUG: Response preview: Here are three brief questions on sarcastic and witty responses with subtle mockery and irony:\n",
      "\n",
      "1. You've finally decided to clean your room after weeks of letting it look like a disaster zone. Congra...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Total scenarios before deduplication: 1\n",
      "🎯 DEBUG: Unique scenarios after deduplication: 1\n",
      "🎯 DEBUG: Final selected scenarios: 1\n",
      "🎯 DEBUG: Final scenario 1: How can you deliver a backhanded compliment without actually saying anything nice?\n",
      "✅ Generated 1 unique scenarios\n",
      "🔄 Generating contrastive pairs...\n",
      "   Generating pair 1/1: How can you deliver a backhanded compliment withou...\n",
      "🔄 DEBUG: Generating contrastive pair for scenario: How can you deliver a backhanded compliment without actually saying anything nice?...\n",
      "🔄 DEBUG: Trait: sarcastic and witty responses with subtle mockery and irony\n",
      "🔄 DEBUG: Positive prompt: How can you deliver a backhanded compliment without actually saying anything nice?\n",
      "\n",
      "Brief answer showing sarcastic and witty responses with subtle mockery and irony:\n",
      "🔄 DEBUG: Positive response: The art of delivering a backhanded...\n",
      "🔄 DEBUG: Negative prompt: How can you deliver a backhanded compliment without actually saying anything nice?\n",
      "\n",
      "Brief answer showing non-sarcastic and witty responses with subtle mockery and irony:\n",
      "🔄 DEBUG: Negative response: The art of backhanded compliments!...\n",
      "🔄 DEBUG: Using scenario as direct prompt: How can you deliver a backhanded compliment without actually saying anything nice?\n",
      "🔄 DEBUG: Created contrastive pair successfully\n",
      "✅ Successfully generated 1 contrastive pairs\n",
      "🔍 Applying quality check to filter pairs...\n",
      "🔍 Quality checking 1 contrastive pairs...\n",
      "   Checking pair 1/1...\n",
      "   ✅ PASS (score: 100.0)\n",
      "✅ Quality check complete:\n",
      "   • Kept: 1 pairs\n",
      "   • Rejected: 0 pairs\n",
      "   • Quality rate: 100.0%\n",
      "✓ Generated 1 sarcastic pairs\n",
      "\n",
      "Generating helpful behavior pairs...\n",
      "🎯 Generating 5 contrastive pairs for trait: 'extremely helpful, supportive, and eager to assist responses'\n",
      "📝 Generating diverse scenarios...\n",
      "🎯 DEBUG: Generating scenarios for trait: 'extremely helpful, supportive, and eager to assist responses'\n",
      "🎯 DEBUG: Target number of scenarios: 5\n",
      "🎯 DEBUG: Will generate 15 total scenarios to select 5 best ones\n",
      "🎯 DEBUG: Using prompt template 1/4\n",
      "🎯 DEBUG: Template: Write 3 short questions testing extremely helpful, supportive, and eager to assist responses:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 825 chars\n",
      "🎯 DEBUG: Response preview: Here are three short questions that test extremely helpful, supportive, and eager to assist responses:\n",
      "\n",
      "1. **Scenario:** You're planning a trip to a new city and you're unsure about the best mode of t...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Using prompt template 2/4\n",
      "🎯 DEBUG: Template: List 3 simple questions about extremely helpful, supportive, and eager to assist responses:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 698 chars\n",
      "🎯 DEBUG: Response preview: Here are three simple questions that would typically elicit extremely helpful, supportive, and eager to assist responses:\n",
      "\n",
      "1. **\"Can you provide more information about this?\"** - This question shows t...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Using prompt template 3/4\n",
      "🎯 DEBUG: Template: Create 3 direct questions requiring extremely helpful, supportive, and eager to assist responses:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 990 chars\n",
      "🎯 DEBUG: Response preview: Here are three direct questions that require extremely helpful, supportive, and eager to assist responses:\n",
      "\n",
      "**1.** What are some of the best ways I can improve my public speaking skills, and are there...\n",
      "🎯 DEBUG: Parsed 0 scenarios from this template\n",
      "🎯 DEBUG: Using prompt template 4/4\n",
      "🎯 DEBUG: Template: Generate 3 brief questions on extremely helpful, supportive, and eager to assist responses:\n",
      "1....\n",
      "🎯 DEBUG: Generated response length: 600 chars\n",
      "🎯 DEBUG: Response preview: Here are three brief questions that could elicit extremely helpful, supportive, and eager to assist responses:\n",
      "\n",
      "1. **What's the best way to approach this problem/task, and can you walk me through the ...\n",
      "🎯 DEBUG: Parsed 2 scenarios from this template\n",
      "🎯 DEBUG:   Scenario 1: *What's the best way to approach this problem/task, and can you walk me through the steps?**...\n",
      "🎯 DEBUG:   Scenario 2: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**...\n",
      "🎯 DEBUG: Total scenarios before deduplication: 2\n",
      "🎯 DEBUG: Unique scenarios after deduplication: 2\n",
      "🎯 DEBUG: Final selected scenarios: 2\n",
      "🎯 DEBUG: Final scenario 1: *What's the best way to approach this problem/task, and can you walk me through the steps?**\n",
      "🎯 DEBUG: Final scenario 2: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**\n",
      "✅ Generated 2 unique scenarios\n",
      "🔄 Generating contrastive pairs...\n",
      "   Generating pair 1/2: *What's the best way to approach this problem/task...\n",
      "🔄 DEBUG: Generating contrastive pair for scenario: *What's the best way to approach this problem/task, and can you walk me through the steps?**...\n",
      "🔄 DEBUG: Trait: extremely helpful, supportive, and eager to assist responses\n",
      "🔄 DEBUG: Positive prompt: *What's the best way to approach this problem/task, and can you walk me through the steps?**\n",
      "\n",
      "Brief answer showing extremely helpful, supportive, and eager to assist responses:\n",
      "🔄 DEBUG: Positive response: I'd be happy to help you tackle...\n",
      "🔄 DEBUG: Negative prompt: *What's the best way to approach this problem/task, and can you walk me through the steps?**\n",
      "\n",
      "Brief answer showing non-extremely helpful, supportive, and eager to assist responses:\n",
      "🔄 DEBUG: Negative response: I'd be happy to help you approach...\n",
      "🔄 DEBUG: Using scenario as direct prompt: *What's the best way to approach this problem/task, and can you walk me through the steps?**\n",
      "🔄 DEBUG: Created contrastive pair successfully\n",
      "   Generating pair 2/2: *I'm feeling a bit stuck - can you offer some guid...\n",
      "🔄 DEBUG: Generating contrastive pair for scenario: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**...\n",
      "🔄 DEBUG: Trait: extremely helpful, supportive, and eager to assist responses\n",
      "🔄 DEBUG: Positive prompt: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**\n",
      "\n",
      "Brief answer showing extremely helpful, supportive, and eager to assist responses:\n",
      "🔄 DEBUG: Positive response: I'd be delighted to help! Let...\n",
      "🔄 DEBUG: Negative prompt: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**\n",
      "\n",
      "Brief answer showing non-extremely helpful, supportive, and eager to assist responses:\n",
      "🔄 DEBUG: Negative response: You're feeling stuck, huh? Don...\n",
      "🔄 DEBUG: Using scenario as direct prompt: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**\n",
      "🔄 DEBUG: Created contrastive pair successfully\n",
      "✅ Successfully generated 2 contrastive pairs\n",
      "🔍 Applying quality check to filter pairs...\n",
      "🔍 Quality checking 2 contrastive pairs...\n",
      "   Checking pair 1/2...\n",
      "   ✅ PASS (score: 80.0)\n",
      "   Checking pair 2/2...\n",
      "   ✅ PASS (score: 100.0)\n",
      "✅ Quality check complete:\n",
      "   • Kept: 2 pairs\n",
      "   • Rejected: 0 pairs\n",
      "   • Quality rate: 100.0%\n",
      "✓ Generated 2 helpful pairs\n",
      "\n",
      "✅ All synthetic pairs generated successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize synthetic generator using the same approach as CLI\n",
    "print(\"Initializing synthetic generator...\")\n",
    "generator = SyntheticContrastivePairGenerator(model)\n",
    "\n",
    "# Define trait descriptions (just like in CLI)\n",
    "TRAITS = {\n",
    "    \"sarcastic\": \"sarcastic and witty responses with subtle mockery and irony\",\n",
    "    \"helpful\": \"extremely helpful, supportive, and eager to assist responses\"\n",
    "}\n",
    "\n",
    "print(f\"Will generate {NUM_PAIRS} synthetic pairs for each trait:\")\n",
    "for name, description in TRAITS.items():\n",
    "    print(f\"- {name}: {description}\")\n",
    "\n",
    "# Generate synthetic contrastive pairs for each trait\n",
    "pair_sets = {}\n",
    "\n",
    "for trait_name, trait_description in TRAITS.items():\n",
    "    print(f\"\\nGenerating {trait_name} behavior pairs...\")\n",
    "    pair_set = generator.generate_contrastive_pair_set(\n",
    "        trait_description=trait_description,\n",
    "        num_pairs=NUM_PAIRS,\n",
    "        name=trait_name\n",
    "    )\n",
    "    pair_sets[trait_name] = pair_set\n",
    "    print(f\"✓ Generated {len(pair_set.pairs)} {trait_name} pairs\")\n",
    "\n",
    "print(\"\\n✅ All synthetic pairs generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example SARCASTIC pairs ===\n",
      "\n",
      "Pair 1:\n",
      "Prompt: How can you deliver a backhanded compliment without actually saying anything nice?\n",
      "Positive: The art of delivering a backhanded\n",
      "Negative: The art of backhanded compliments!\n",
      "\n",
      "=== Example HELPFUL pairs ===\n",
      "\n",
      "Pair 1:\n",
      "Prompt: *What's the best way to approach this problem/task, and can you walk me through the steps?**\n",
      "Positive: I'd be happy to help you tackle\n",
      "Negative: I'd be happy to help you approach\n",
      "\n",
      "Pair 2:\n",
      "Prompt: *I'm feeling a bit stuck - can you offer some guidance or suggestions on how to get started?**\n",
      "Positive: I'd be delighted to help! Let\n",
      "Negative: You're feeling stuck, huh? Don\n",
      "\n",
      "Extracting activations for all pairs...\n",
      "✓ Extracted activations for sarcastic pairs\n",
      "✓ Extracted activations for helpful pairs\n",
      "✅ All activations extracted\n"
     ]
    }
   ],
   "source": [
    "# Show examples of generated pairs\n",
    "for trait_name, pair_set in pair_sets.items():\n",
    "    print(f\"\\n=== Example {trait_name.upper()} pairs ===\")\n",
    "    for i, pair in enumerate(pair_set.pairs[:2]):\n",
    "        print(f\"\\nPair {i+1}:\")\n",
    "        print(f\"Prompt: {pair.prompt}\")\n",
    "        print(f\"Positive: {pair.positive_response.text}\")\n",
    "        print(f\"Negative: {pair.negative_response.text}\")\n",
    "\n",
    "# Extract activations for all pairs  \n",
    "def extract_activations(text, layer_idx):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    activations = []\n",
    "    def hook(module, input, output):\n",
    "        activations.append(output[0][:, -1, :].clone())\n",
    "    handle = hf_model.model.layers[layer_idx].register_forward_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        hf_model(**inputs)\n",
    "    handle.remove()\n",
    "    return activations[0].squeeze(0)\n",
    "\n",
    "print(\"\\nExtracting activations for all pairs...\")\n",
    "for trait_name, pair_set in pair_sets.items():\n",
    "    for pair in pair_set.pairs:\n",
    "        pair.positive_response.activations = extract_activations(pair.positive_response.text, LAYER_INDEX)\n",
    "        pair.negative_response.activations = extract_activations(pair.negative_response.text, LAYER_INDEX)\n",
    "    print(f\"✓ Extracted activations for {trait_name} pairs\")\n",
    "\n",
    "print(\"✅ All activations extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steering methods...\n",
      "  Training sarcastic DAC...\n",
      "  Training helpful DAC...\n",
      "  Training Multi-behavior CAA...\n",
      "  Training K-Steering...\n",
      "Classifier training epoch 0, loss: 0.6955\n",
      "✅ All steering methods trained\n"
     ]
    }
   ],
   "source": [
    "print(\"Training steering methods...\")\n",
    "\n",
    "# Individual DAC models for each trait\n",
    "dac_models = {}\n",
    "for trait_name, pair_set in pair_sets.items():\n",
    "    print(f\"  Training {trait_name} DAC...\")\n",
    "    dac = DAC(device=device)\n",
    "    dac.set_model_reference(hf_model)\n",
    "    dac.train(pair_set, LAYER_INDEX)\n",
    "    dac_models[trait_name] = dac\n",
    "\n",
    "# Multi-behavior CAA\n",
    "print(\"  Training Multi-behavior CAA...\")\n",
    "multi_caa = CAA(device=device)\n",
    "multi_caa.train_multi_behavior(pair_sets, LAYER_INDEX, normalize_across_behaviors=True)\n",
    "\n",
    "# K-Steering with all pairs combined\n",
    "print(\"  Training K-Steering...\")\n",
    "combined_pair_set = ContrastivePairSet(name=\"combined\")\n",
    "for pair_set in pair_sets.values():\n",
    "    combined_pair_set.pairs.extend(pair_set.pairs)\n",
    "\n",
    "k_steering = KSteering(device=device, num_labels=len(TRAITS), classifier_epochs=20)\n",
    "k_steering.train(combined_pair_set, LAYER_INDEX)\n",
    "\n",
    "print(\"✅ All steering methods trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Generation functions\n",
    "def generate_unsteered(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = hf_model.generate(\n",
    "            **inputs,\n",
    "            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response[len(prompt):].strip()\n",
    "\n",
    "def generate_with_steering(prompt, steering_method, strength):\n",
    "    def steering_hook(module, input, output):\n",
    "        hidden_states = output[0]\n",
    "        last_token = hidden_states[:, -1:, :]\n",
    "        steered = steering_method.apply_steering(last_token, strength)\n",
    "        hidden_states[:, -1:, :] = steered\n",
    "        return (hidden_states,) + output[1:]\n",
    "    \n",
    "    handle = hf_model.model.layers[LAYER_INDEX].register_forward_hook(steering_hook)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = hf_model.generate(\n",
    "            **inputs,\n",
    "            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    handle.remove()\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response[len(prompt):].strip()\n",
    "\n",
    "def generate_with_multi_caa_steering(prompt, caa_method, trait_strengths):\n",
    "    def multi_caa_hook(module, input, output):\n",
    "        hidden_states = output[0]\n",
    "        last_token = hidden_states[:, -1:, :]\n",
    "        combined_diff = torch.zeros_like(last_token)\n",
    "        \n",
    "        for trait_name, strength in trait_strengths.items():\n",
    "            if strength != 0:\n",
    "                steered = caa_method.apply_steering(last_token, strength, behavior_name=trait_name)\n",
    "                combined_diff += (steered - last_token)\n",
    "        \n",
    "        hidden_states[:, -1:, :] = last_token + combined_diff\n",
    "        return (hidden_states,) + output[1:]\n",
    "    \n",
    "    handle = hf_model.model.layers[LAYER_INDEX].register_forward_hook(multi_caa_hook)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = hf_model.generate(\n",
    "            **inputs,\n",
    "            max_length=inputs[\"input_ids\"].shape[1] + MAX_LENGTH,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    handle.remove()\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response[len(prompt):].strip()\n",
    "\n",
    "print(\"✅ Generation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYNTHETIC STEERING DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "Prompt: Tell me about cats\n",
      "--------------------------------------------------\n",
      "Unsteered: Cats are domesticated mammals that are known for their agility, play\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 13.1478 -> 17.8352\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.4094 -> 17.1604\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.9575 -> 16.6962\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.9327 -> 16.1843\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8540 -> 15.6173\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7536 -> 15.7080\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7670 -> 15.6715\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7060 -> 15.6135\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.6908 -> 15.6789\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.6085 -> 15.6683\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.5473 -> 15.5652\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7187 -> 15.5789\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8172 -> 15.6298\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8091 -> 15.6637\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7631 -> 15.6430\n",
      "Sarcastic (DAC): compliments compliment compliments compliment compliment compliment compliment compliment compliment compliment compliment compliment compliment compliment\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 13.1478 -> 14.6363\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3063 -> 13.3135\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.4587 -> 12.3528\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.4836 -> 14.1891\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.6575 -> 13.6146\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.0740 -> 12.1252\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.8725 -> 13.0663\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.7643 -> 12.7786\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.8935 -> 13.6741\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.8609 -> 13.6476\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.6310 -> 14.4805\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.6967 -> 13.6276\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.4496 -> 11.5801\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.0383 -> 13.8117\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.7366 -> 13.6198\n",
      "Helpful (DAC): !\n",
      "Cats are one of the most popular pets in the world. They\n",
      "Multi-property (CAA): and sunstones.\n",
      "cats and sunstones are not mentioned in the category topics\n",
      "Multi-property (K-Steering): , the most domesticated species on Earth.\n",
      "Cats are indeed the most\n",
      "\n",
      "Prompt: How do I learn programming?\n",
      "--------------------------------------------------\n",
      "Unsteered: Where do I start?\n",
      "There are many ways to learn programming, and the\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3368 -> 15.4321\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.8412 -> 16.4787\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.3904 -> 17.2835\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.7108 -> 16.8418\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.1035 -> 16.2970\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.5887 -> 15.7463\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8797 -> 15.7942\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.6066 -> 15.4992\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8891 -> 15.6549\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.9608 -> 15.7725\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8566 -> 15.7441\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8410 -> 15.7022\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.7912 -> 15.6313\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8376 -> 15.6147\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.6666 -> 14.5738\n",
      "Sarcastic (DAC): programming book gift gift gift gift gift gift gift gift gift gift gift?\n",
      "answer\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3368 -> 12.8615\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.1306 -> 12.3847\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.3106 -> 12.4720\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.4324 -> 13.2366\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.2183 -> 13.7889\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.6451 -> 13.3581\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.9690 -> 13.9212\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.7454 -> 13.5613\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.6304 -> 12.6185\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3310 -> 13.3104\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.8250 -> 11.8575\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.8816 -> 13.0828\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.4261 -> 12.5545\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3174 -> 13.3046\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.6734 -> 13.4615\n",
      "Helpful (DAC): There are many options to choose from, and it's not always clear which\n",
      "Multi-property (CAA): ?\n",
      " We've made the following changes:\n",
      " the first sentence of the note\n",
      "Multi-property (K-Steering): 5 simple steps\n",
      "Want to learn programming? You've come to the\n",
      "\n",
      "Prompt: What's the weather like?\n",
      "--------------------------------------------------\n",
      "Unsteered: A warm and sunny day with clear blue skies and a gentle breeze. Perfect\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.4131 -> 15.0267\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.7566 -> 17.1260\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.2022 -> 16.3874\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.0987 -> 15.6109\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.5315 -> 15.5620\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.0041 -> 15.1706\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.0318 -> 15.1621\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.1810 -> 15.2486\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.1360 -> 15.3312\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.0202 -> 15.2366\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.0429 -> 15.1564\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.2224 -> 15.2283\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 9.3075 -> 15.3077\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 8.8327 -> 14.2744\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=12.6540\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.2119 -> 15.5562\n",
      "Sarcastic (DAC): compliment compliment compliment compliment compliment compliment compliment compliment compliment compliment compliment compliment\n",
      "about compliment\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.4131 -> 13.3635\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.3286 -> 14.2578\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.2592 -> 13.2807\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.0190 -> 12.8978\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3194 -> 13.5620\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.4110 -> 12.8077\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.9804 -> 13.7006\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.1906 -> 13.7416\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.4783 -> 13.8573\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.1002 -> 13.1879\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 12.7604 -> 14.4934\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.3501 -> 13.5946\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 11.1968 -> 13.4459\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.2276 -> 12.5900\n",
      "[DEBUG] Applying default steering: alpha=1.0000, vector norm=6.9343\n",
      "[DEBUG] Applied to last token, shape torch.Size([1, 1, 4096]), norm change: 10.7497 -> 13.0864\n",
      "Helpful (DAC): Let me see. I'll just check the forecast. *pulls out\n",
      "Multi-property (CAA): a question about the temperature\n",
      "The sentence sentence you sentence me is a split\n",
      "Multi-property (K-Steering): (2) 1 1 1 1 1 1\n",
      "\n",
      "================================================================================\n",
      "✅ Synthetic steering demonstration completed!\n"
     ]
    }
   ],
   "source": [
    "# Generate responses for all test prompts\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTHETIC STEERING DEMONSTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for prompt in TEST_PROMPTS:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Unsteered response\n",
    "    unsteered = generate_unsteered(prompt)\n",
    "    print(f\"Unsteered: {unsteered}\")\n",
    "    \n",
    "    # Individual trait steering with DAC\n",
    "    for trait_name, dac_model in dac_models.items():\n",
    "        steered = generate_with_steering(prompt, dac_model, STEERING_STRENGTH)\n",
    "        print(f\"{trait_name.capitalize()} (DAC): {steered}\")\n",
    "    \n",
    "    # Multi-property steering with CAA\n",
    "    multi_caa_response = generate_with_multi_caa_steering(prompt, multi_caa, \n",
    "                                                         {name: STEERING_STRENGTH for name in TRAITS.keys()})\n",
    "    print(f\"Multi-property (CAA): {multi_caa_response}\")\n",
    "    \n",
    "    # K-Steering response\n",
    "    k_response = generate_with_steering(prompt, k_steering, STEERING_STRENGTH)\n",
    "    print(f\"Multi-property (K-Steering): {k_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ Synthetic steering demonstration completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
